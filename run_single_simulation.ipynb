{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHOBS-IE-100\n",
    "## Notionally Optimal, 100% Wind+Hydrogen+Other+Battery+Solar Electricity System for Ireland (IE)\n",
    "\n",
    "- **Project:** [OESM-IE](http://ecrn.eeng.dcu.ie/projects/oesm-ie)\n",
    "- **Funding:** [Sustainable Energy Authority of Ireland (SEAI) Research, Development and Demonstration Programme](https://www.seai.ie/grants/research-funding/research-development-and-demonstration-fund/), award reference SEAI RDD/00246 2018.\n",
    "- **Author:** Barry McMullin, barry.mcmullin@dcu.ie\n",
    "- **Last modified:** 03 June 2020\n",
    "- **Â© 2020:** [Dublin City University](http://www.dcu.ie/)\n",
    "- **Licence:** [GNU GENERAL PUBLIC LICENSE Version 3](https://www.gnu.org/licenses/gpl-3.0.en.html)\n",
    "\n",
    "This is a derived from: [Optimal Wind+Hydrogen+Other+Battery+Solar (WHOBS) electricity systems for European countries](https://github.com/PyPSA/WHOBS)\n",
    "\n",
    "Download the [Jupyter notebook](https://jupyter.org/) at: **TODO**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction/motivation\n",
    "\n",
    "[WHOBS](https://github.com/PyPSA/WHOBS), and the associated interactive web application [model.energy](https://model.energy/), allows modelling of notionally optimised \"firm\" electricity generation for a given level of (constant/\"baseload\") capacity, based exclusively on *variable* renewable (VRE: here limited to wind and solar) sources, coupled with hydrogen and/or battery storage (to cover \"when the wind doesn't blow and the sun doesn't shine\"). \n",
    "\n",
    "Wind and solar resource variability is configured for states within Europe using historical data from [Renewables.ninja](https://www.renewables.ninja/) ([model.energy](https://model.energy/) extends this coverage to global geographical locations using other data sources).\n",
    "\n",
    "**WHOBS-IE-100** adapts WHOBS to model delivery of **100%** of electricity demand for one particular European country (**Ireland**), based on [historical load data](http://www.eirgridgroup.com/how-the-grid-works/renewables/) from the [Irish Transmission System Operator (TSO) eirgrid](http://www.eirgridgroup.com/).\n",
    "\n",
    "This result illustrates the (rough) trade-off between:\n",
    "\n",
    "- Raw VRE *overprovision* (building more VRE capacity than can be directly dispatched at all times, but meaning that more demand can be covered directly by instantaneous VRE generations)\n",
    "- Dispatch down (discarding some generation when it is in excess of instantaneous load)\n",
    "- Storage (storing some generation when it is in excess of instantaneous load)\n",
    "    - Short term, high efficiency storage: battery\n",
    "    - Long term, low efficiency storage: hydrogen\n",
    "\n",
    "This toy model assumes a completely isolated grid (no external interconnection).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "+ Create/release as github project: add link in metadata block at top?\n",
    "+ Link to the [detailed caveats in the WHOBS README](https://github.com/PyPSA/WHOBS#warnings).\n",
    "+ Add more cautions/, including:\n",
    "    - *multi-annual* variability in generation and load\n",
    "    - constraint as well as curtailment \n",
    "    - system stability (traditional SNSP!) \n",
    "    - onshore wind only (offshore would be less variable but generally still more expensive)\n",
    "    - limited/no salt cavern underground storage within the IE jurisdiction (there is some in NI, but [currently targetted for NG storage!](https://www.infrastrataplc.com/projects/islandmagee-energy/)\n",
    "    - unclear whether the proposed (solved) wind and solar capacity is even feasible within the jurisdiction\n",
    "    - certain \"low carbon\", \"firm\" generation sources are deliberately omitted: nuclear, fossil fuel with CCS and bioenergy: it is likely that a (near) zero-$CO_2$ system could be achieved at lower cost by allowing such a wider range of options\n",
    "    - etc. etc...\n",
    "+ Batteries are allowed a tech-generic lifetime of 25 years (in assumptions .csv) - which seems a bit generous? Though may not change the results all that much...\n",
    "+ Add some (simplistic) model of interconnection: e.g. as a `StorageUnit` with `cyclic=True`, fixed `p_nom`, efficiency somewhat reflective of real IC losses (to UK/France). This is easier than trying to pick a price for a market import/export model (though it excludes nett exports as a trade opportunity...). Skates over the NI integration connection, which arguably deserves finer grained representation (given similar wind var profile).\n",
    "+ Add some representation of offshore wind as well as onshore; set `p_nom_extendable_max` for onshore, based on actual SEAI estimates. Note that offshore variability pattern is expected to be different from onshore (potential high capacity factor, absent dispatch down).\n",
    "+ Add some notional representation of grid losses (matching typical SEAI/Eirgrid levels?).\n",
    "+ Add some crude capability of changing average load level for target year (linear, exponential, whatever...)\n",
    "+ Add more flexible options on temporal resolution - not just 1 or 3 hours, but 6, 12, 24 hours?\n",
    "+ Add H2P OCGT (as well as CCGT)? Let `lopf()` optimise between OCGT and CCGT (will it all go to one?).\n",
    "+ Instead of a H2 steel tank storage being binary, leave it available unconditionally, but (optionally) set an `e_extendable_max` limit on H2 salt cavern underground storage (possibly loosely based on actual geology available in NI).\n",
    "+ Add a \"middle tier\" H2 storage option (between steel tank and salt cavern underground): [loosely based on ammonia tank storage](https://ammoniaindustry.com/ammonia-for-energy-storage-economic-and-technical-analysis/)?\n",
    "+ Of course, extending into heating and transport sectors is also on the agenda!\n",
    "+ Refactor the \"scenario\" concept:\n",
    "    - Incorporate `frequency` (properly, `time_resolution` or `time_step` or `snapshot_interval`?).\n",
    "    - Incorporate dispatch priority among VRE (solar/wind) as a scenario variable\n",
    "    - Currently \"hydrogen\" and \"hydrogen steel tank\" are effectively boolean scenario variables, though not expressly incorporated in the scenario mechanism/naming. Maybe make \"all\" the discrete technologies boolean in this sense, with a scenario tech substring something like: `WSHTB` (Wind|Solar|H2|Tank|Battery)?\n",
    "    - Refactor so that generic `network` only constructed once, and then specific details varied by scenario; should yield a little performance improvement/responsivity...\n",
    "+ Possibly refactor to remove the `ct` (\"country\"?) use? This is inherited from WHOBS, which genuinely has configuration capability for a variety of countries; but WHOBS-IE-100 really is hard-wired already for IE?\n",
    "+ Figure out/refactor exactly the way the plotting works...\n",
    "+ Refactor the import of third-party data files (Renewables.ninja and Eirgrid) to automate, with local caching...\n",
    "+ Create a single line diagram illustration (SLD)\n",
    "+ Screencast tutorial/explanation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pyomo.environ import Constraint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_float(x) :\n",
    "    return (F\"{x: 6.2f}\")\n",
    "    \n",
    "pd.set_option('float_format', fmt_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty DataFrame to collect run configuration\n",
    "run_configs = pd.DataFrame()\n",
    "\n",
    "# Initialise empty DataFrame to collect run output stats\n",
    "run_stats = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotsize in notebook\n",
    "# https://www.mikulskibartosz.name/how-to-change-plot-size-in-jupyter-notebook/\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHOBS was generic to multiple countries coded by `ct`; but here we will be \n",
    "# hard-wired to `IE` in other ways, so set `ct` to match in (legacy) WHOBS code.\n",
    "# Essential usage is to index into renewables.ninja datasets.\n",
    "\n",
    "ct = \"IE\"\n",
    "solver_name = \"cbc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required data\n",
    "\n",
    "### Wind and solar resource variabilities\n",
    "\n",
    "From [Renewables.ninja Downloads](https://www.renewables.ninja/downloads):\n",
    "\n",
    "- Solar time series \"ninja_pv_europe_v1.1_sarah.csv\" from [PV v1.1 Europe (.zip)](https://www.renewables.ninja/static/downloads/ninja_europe_pv_v1.1.zip)\n",
    "- Wind time series \"ninja_wind_europe_v1.1_current_on-offshore.csv\" from [Wind v1.1 Europe (.zip)](https://www.renewables.ninja/static/downloads/ninja_europe_wind_v1.1.zip)\n",
    "\n",
    "### IE Load (electricity demand) variability\n",
    "\n",
    "From [eirgrid System and Renewable Data Reports](http://www.eirgridgroup.com/how-the-grid-works/renewables/):\n",
    "\n",
    "- [System-Data-Qtr-Hourly-2018-2019.xlsx](http://www.eirgridgroup.com/site-files/library/EirGrid/System-Data-Qtr-Hourly-2018-2019.xlsx) \n",
    "- [System-Data-Qtr-Hourly-2016-2017.xlsx](http://www.eirgridgroup.com/site-files/library/EirGrid/System-Data-Qtr-Hourly-2016-2017.xlsx)\n",
    "- [System-Data-Qtr-Hourly-2014-2015.xlsx](http://www.eirgridgroup.com/site-files/library/EirGrid/System-Data-Qtr-Hourly-2014-2015.xlsx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in wind and solar variability data\n",
    "\n",
    "**TODO:** Ideally, recode this to check for local copy, and, if not available, automatically download \n",
    "and extract the required .csv from the .zip in each case; but for the moment, just assume there is are local copies of the .csv files already available.\n",
    "\n",
    "**Alternative approach?** An alterative to using renewables ninja (specfically for wind) would be to extract the variability data (of actual wind generation) from historical eirgrid data. This would reflect the performance of the IE wind fleet as of whatever historical date was used: which may be a good thing or a bad thing of course (since that is almost 100% onshore for the moment, it is \"biased against\" offshore - arguably?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rninja_base_url = \"https://www.renewables.ninja/static/downloads/\"\n",
    "r_ninja_base_url = 'ninja/' # Actually already downloaded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solar_pv_zip_file = 'ninja_europe_pv_v1.1.zip'\n",
    "#solar_pv_zip_url = r_ninja_base_url + solar_pv_zip_file\n",
    "\n",
    "solar_pv_csv_file = 'ninja_pv_europe_v1.1_sarah.csv'\n",
    "solar_pv_csv_url = r_ninja_base_url + solar_pv_csv_file\n",
    "\n",
    "#read in renewables.ninja solar time series\n",
    "solar_pu_raw = pd.read_csv(solar_pv_csv_url,\n",
    "                       index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wind_zip_file = 'ninja_europe_wind_v1.1.zip'\n",
    "#wind_zip_url = r_ninja_base_url + wind_zip_file\n",
    "\n",
    "wind_csv_file = 'ninja_wind_europe_v1.1_current_on-offshore.csv'\n",
    "wind_csv_url = r_ninja_base_url + wind_csv_file\n",
    "\n",
    "#read in renewables.ninja wind time series\n",
    "wind_pu_raw = pd.read_csv(wind_csv_url,\n",
    "                       index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and preprocess load variability data (via Ireland TSO, [EirGrid](http://www.eirgridgroup.com/))\n",
    "\n",
    "We start with [historical data inputs from EirGrid](http://www.eirgridgroup.com/how-the-grid-works/renewables/) which show 15-minute time series for:\n",
    "\n",
    "- wind availability\n",
    "- wind generation\n",
    "- total generation\n",
    "- total load\n",
    "\n",
    "broken out by:\n",
    "\n",
    "- IE (Republic of Ireland) only\n",
    "- NI (Northern Ireland) only\n",
    "\n",
    "As this particular notebook in only relying on this data for an example of \"typical\" annual variability in aggregate load we select the data for **IE (Republic of Ireland) only**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve example eirgrid system data into a pd.dataframe\n",
    "\n",
    "# If file already available locally, can point at that; otherwise use the web url\n",
    "# (i.e. uncomment one or the other of the following two statements).\n",
    "\n",
    "#eirgrid_base_url = \"http://www.eirgridgroup.com/site-files/library/EirGrid/\"\n",
    "eirgrid_base_url = \"eirgrid/\"\n",
    "\n",
    "load_data_filename = \"System-Data-Qtr-Hourly-2014-2015.xlsx\"\n",
    "load_data_url = eirgrid_base_url + load_data_filename\n",
    "\n",
    "cols = ['DateTime', 'GMT Offset', \"IE Demand\"]\n",
    "\n",
    "load_data_raw = pd.read_excel(load_data_url, usecols = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(load_data_raw.dtypes)\n",
    "print(load_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the timestamps...\n",
    "\n",
    "The raw eirgrid data has one column showing localtime (`DateTime`, type `pd.Timestamp`, holding \"naive\" timestamps - no recorded timezone) and a separate column showing the offset, in hours, from UTC for each individual row (`GMT Offset`). It will be simpler here to convert all the `DateTime` values to UTC (and explicitly having the UTC timezone).\n",
    "\n",
    "We can then dispense with the `GMT Offset` column as it is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def tz_fix(row):\n",
    "  try:\n",
    "    naive_timestamp = row['DateTime']\n",
    "    gmt_offset = row['GMT Offset'] \n",
    "    utc_timestamp = naive_timestamp - timedelta(hours=float(gmt_offset))\n",
    "        # float() conversion required for timedelta() argument!\n",
    "        # Must SUBTRACT the GMT Offset to get GMT/UTC\n",
    "    row['DateTime'] = utc_timestamp.tz_localize('UTC')\n",
    "  except Exception as inst:\n",
    "    print(F\"Exception:\\n {row}\")\n",
    "    print(inst)\n",
    "  return row\n",
    "\n",
    "# This may be rather be slow for a big dataset...\n",
    "load_data_raw = load_data_raw.apply(tz_fix, axis=1).drop(columns='GMT Offset')\n",
    "\n",
    "load_data_raw.set_index('DateTime', verify_integrity=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some (raw) load profile stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_raw = load_data_raw.loc[:,'IE Demand'] # convert to pd.Series\n",
    "\n",
    "load_raw_max = load_raw.max()\n",
    "load_raw_mean = load_raw.mean()\n",
    "load_raw_min = load_raw.min()\n",
    "load_raw_e = load_raw.sum()*0.25 # Raw time interval is 15m == 0.25h\n",
    "\n",
    "print(F\"load_raw_max: {(load_raw_max/1.0e3) : 6.3f} GW\")\n",
    "print(F\"load_raw_mean: {(load_raw_mean/1.0e3) : 6.3f} GW\")\n",
    "print(F\"load_raw_min: {(load_raw_min/1.0e3) : 6.3f} GW\")\n",
    "print(F\"load_raw_e: {(load_raw_e/1.0e6) : 6.3f} TWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality checks?\n",
    "\n",
    "Minimal data quality check: make sure [we have no missing values](https://chartio.com/resources/tutorials/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe/) (either `None` or `NaN`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not load_data_raw.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(load_raw)\n",
    "\n",
    "#print(F\"load_max: {(load_max/1.0e3) : 6.3f} GW\")\n",
    "#print(F\"load_mean: {(load_mean/1.0e3) : 6.3f} GW\")\n",
    "#print(F\"load_min: {(load_min/1.0e3) : 6.3f} GW\")\n",
    "#print(F\"load_e: {(load_e/1.0e6) : 6.3f} TWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: need some docs/explanation/sources for this calculation?\n",
    "\n",
    "def annuity(lifetime, rate):\n",
    "    if rate == 0.0 :\n",
    "        return 1.0/lifetime\n",
    "    else:\n",
    "        return rate/(1.0 - (1.0 / (1.0 + rate)**lifetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_assumptions(Nyears=1,usd_to_eur=1/1.2,assumptions_year=2020):\n",
    "    \"\"\"set all asset assumptions and other parameters\"\"\"\n",
    "\n",
    "    assumptions = pd.read_csv(\"assumptions.csv\",index_col=list(range(3))).sort_index()\n",
    "\n",
    "    #correct units to MW and EUR\n",
    "    assumptions.loc[assumptions.unit.str.contains(\"/kW\"),\"value\"]*=1e3\n",
    "    assumptions.loc[assumptions.unit.str.contains(\"USD\"),\"value\"]*=usd_to_eur\n",
    "\n",
    "    assumptions = assumptions.loc[idx[:,assumptions_year,:],\n",
    "                                  \"value\"].unstack(level=2).groupby(level=\"technology\").sum(min_count=1)\n",
    "\n",
    "    #fill defaults\n",
    "    assumptions = assumptions.fillna({\"FOM\" : assumptions.at[\"default\",\"FOM\"],\n",
    "                                      \"discount rate\" : assumptions.at[\"default\",\"discount rate\"],\n",
    "                                      \"lifetime\" : assumptions.at[\"default\",\"lifetime\"]})\n",
    "\n",
    "    #annualise investment costs, add FOM\n",
    "    assumptions[\"fixed\"] = [(annuity(v[\"lifetime\"],v[\"discount rate\"]) + \n",
    "                             v[\"FOM\"]/100.)*v[\"investment\"]*Nyears for i,v in assumptions.iterrows()]\n",
    "\n",
    "    return assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_network(run_id):\n",
    "\n",
    "    snapshot_interval = int(run_configs.loc['snapshot_interval',run_id])\n",
    "    weather_year_start = int(run_configs.loc['weather_year_start',run_id])\n",
    "    weather_year_end = int(run_configs.loc['weather_year_end',run_id])\n",
    "    assumptions_year = int(run_configs.loc['assumptions_year',run_id])\n",
    "    Nyears = weather_year_end - weather_year_start + 1\n",
    "\n",
    "    assumptions = prepare_assumptions(Nyears=Nyears,\n",
    "                                      assumptions_year=assumptions_year,\n",
    "                                      usd_to_eur=run_configs.loc['usd_to_eur',run_id])\n",
    "\n",
    "    load_year_start = int(run_configs.loc['load_year_start',run_id])\n",
    "    load_date_start = \"{}-01-01 00:00\".format(load_year_start)\n",
    "    load_year_end = int(run_configs.loc['load_year_end',run_id])\n",
    "    load_date_end = \"{}-12-31 23:59\".format(load_year_end)\n",
    "    load = load_raw.loc[load_date_start:load_date_end]\n",
    "    # FIXME: need to make sure the duration of load timeseries matches that of the\n",
    "    # the number of snapshots? Perhaps replace separate weather and load \"end_date\" \n",
    "    # settings with a single, shared, \"duration\" or \"Nyears\" setting?\n",
    "\n",
    "    solar_pu = solar_pu_raw.resample(str(snapshot_interval)+\"H\").mean()\n",
    "    wind_pu = wind_pu_raw.resample(str(snapshot_interval)+\"H\").mean()\n",
    "\n",
    "    load = load.resample(str(snapshot_interval)+\"H\").mean()\n",
    "    # This (re-)sampling will be a bit inefficient if doing multiple runs with the \n",
    "    # same snapshot_interval; but for the moment at least, we don't try to optimise around that\n",
    "    # (e.g. by caching resampled timeseries for later use...)\n",
    "    load = load[~((load.index.month == 2) & (load.index.day == 29))]\n",
    "        # Kludge to filter out \"leap days\" (29th Feb in any year)\n",
    "        # https://stackoverflow.com/questions/34966422/remove-leap-year-day-from-pandas-dataframe\n",
    "   \n",
    "    network = pypsa.Network()\n",
    "\n",
    "    snaps_df = pd.date_range(\"{}-01-01\".format(weather_year_start),\n",
    "                              \"{}-12-31 23:00\".format(weather_year_end),\n",
    "                              freq=str(snapshot_interval)+\"H\").to_frame()\n",
    "    snapshots = snaps_df[~((snaps_df.index.month == 2) & (snaps_df.index.day == 29))].index\n",
    "    # Kludge to filter out \"leap days\" (29th Feb in any year)\n",
    "    \n",
    "    assert(load.count() == snapshots.size)\n",
    "    \n",
    "    network.set_snapshots(snapshots)\n",
    "\n",
    "    network.snapshot_weightings = pd.Series(float(snapshot_interval),index=network.snapshots)\n",
    "\n",
    "    network.add(\"Bus\",ct)\n",
    "    network.add(\"Load\",ct,\n",
    "                bus=ct,\n",
    "                p_set= load.values)\n",
    "\n",
    "    network.add(\"Generator\",ct+\" solar\",\n",
    "                bus=ct,\n",
    "                p_max_pu = solar_pu[ct],\n",
    "                p_nom_extendable = True,\n",
    "                marginal_cost = 0.02, \n",
    "                #Small cost to prefer curtailment to destroying energy in storage, wind curtails before solar\n",
    "                capital_cost = assumptions.at['utility solar PV','fixed'],\n",
    "                #p_nom_max = 0.0\n",
    "               )\n",
    "\n",
    "    network.add(\"Generator\",ct+\" wind\",\n",
    "                bus=ct,\n",
    "                p_max_pu = wind_pu[ct+\"_ON\"],\n",
    "                p_nom_extendable = True,\n",
    "                marginal_cost = 0.01, \n",
    "                #Small cost to prefer curtailment to destroying energy in storage, wind curtails before solar\n",
    "                capital_cost = assumptions.at['onshore wind','fixed'])\n",
    "\n",
    "    network.add(\"Bus\",ct + \" battery\")\n",
    "\n",
    "    network.add(\"Store\",ct + \" battery storage\",\n",
    "                bus = ct + \" battery\",\n",
    "                e_nom_extendable = True,\n",
    "                e_cyclic=True,\n",
    "                capital_cost=assumptions.at['battery storage','fixed'])\n",
    "\n",
    "    network.add(\"Link\",ct + \" battery charge\",\n",
    "                bus0 = ct,\n",
    "                bus1 = ct + \" battery\",\n",
    "                efficiency = assumptions.at['battery inverter','efficiency'],\n",
    "                p_nom_extendable = True,\n",
    "                capital_cost=assumptions.at['battery inverter','fixed'])\n",
    "\n",
    "    network.add(\"Link\",ct + \" battery discharge\",\n",
    "                bus0 = ct + \" battery\",\n",
    "                bus1 = ct,\n",
    "                p_nom_extendable = True,\n",
    "                efficiency = assumptions.at['battery inverter','efficiency'])\n",
    "\n",
    "    def extra_functionality(network,snapshots):\n",
    "        def battery(model):\n",
    "            return (model.link_p_nom[ct + \" battery charge\"] \n",
    "                    == model.link_p_nom[ct + \" battery discharge\"]*network.links.at[ct \n",
    "                    + \" battery charge\",\"efficiency\"])\n",
    "\n",
    "        network.model.battery = Constraint(rule=battery)\n",
    "\n",
    "    network.add(\"Bus\",\n",
    "                     ct + \" H2\",\n",
    "                     carrier=\"H2\")\n",
    "\n",
    "    network.add(\"Link\",\n",
    "                    ct + \" H2 electrolysis\",\n",
    "                    bus1=ct + \" H2\",\n",
    "                    bus0=ct,\n",
    "                    p_nom_extendable=True,\n",
    "                    efficiency=assumptions.at[\"H2 electrolysis\",\"efficiency\"],\n",
    "                    capital_cost=assumptions.at[\"H2 electrolysis\",\"fixed\"])\n",
    "\n",
    "    network.add(\"Link\",\n",
    "                     ct + \" H2 to power\",\n",
    "                     bus0=ct + \" H2\",\n",
    "                     bus1=ct,\n",
    "                     p_nom_extendable=True,\n",
    "                     efficiency=assumptions.at[\"H2 CCGT\",\"efficiency\"],\n",
    "                     capital_cost=assumptions.at[\"H2 CCGT\",\"fixed\"]*assumptions.at[\"H2 CCGT\",\"efficiency\"])  \n",
    "                     #NB: fixed cost is per MWel\n",
    "\n",
    "    network.add(\"Store\",\n",
    "                     ct + \" H2 store underground\",\n",
    "                     bus=ct + \" H2\",\n",
    "                     e_nom_extendable=True,\n",
    "                     e_nom_max = run_configs.loc['h_store_underground_max_e (TWh)',run_id]*1.0e6,\n",
    "                         # TWh -> MWh\n",
    "                     e_cyclic=True,\n",
    "                     capital_cost=assumptions.at[\"H2 underground storage\",\"fixed\"])\n",
    "\n",
    "    network.add(\"Store\",\n",
    "                     ct + \" H2 store tank\",\n",
    "                     bus=ct + \" H2\",\n",
    "                     e_nom_extendable=True,\n",
    "                     e_nom_max = run_configs.loc['h_store_tank_max_e (TWh)',run_id]*1.0e6, \n",
    "                         # TWh -> MWh\n",
    "                     e_cyclic=True,\n",
    "                     capital_cost=assumptions.at[\"H2 steel tank storage\", \"fixed\"])\n",
    "\n",
    "\n",
    "\n",
    "    if solver_name == \"gurobi\":\n",
    "        solver_options = {\"threads\" : 4,\n",
    "                          \"method\" : 2,\n",
    "                          \"crossover\" : 0,\n",
    "                          \"BarConvTol\": 1.e-5,\n",
    "                          \"FeasibilityTol\": 1.e-6 }\n",
    "    else:\n",
    "        solver_options = {}\n",
    "\n",
    "\n",
    "    network.consistency_check()\n",
    "\n",
    "    network.lopf(solver_name=solver_name,\n",
    "                 solver_options=solver_options,\n",
    "                 extra_functionality=extra_functionality)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_run_stats(run_id,network):\n",
    "    \n",
    "    snapshot_interval = run_configs.at['snapshot_interval',run_id]\n",
    "    \n",
    "    total_load_e = (network.loads_t.p.sum().sum() * snapshot_interval)\n",
    "    available_e = (network.generators_t.p_max_pu.multiply(network.generators.p_nom_opt).sum() \n",
    "        * snapshot_interval)\n",
    "    total_available_e = available_e.sum()\n",
    "    dispatched_e = network.generators_t.p.sum() * snapshot_interval\n",
    "    total_dispatched_e = dispatched_e.sum()\n",
    "    undispatched_e = (available_e - dispatched_e)\n",
    "    total_undispatched_e = undispatched_e.sum()\n",
    "    undispatched_frac = undispatched_e/available_e\n",
    "    \n",
    "    run_stats.at[\"System load (TWh)\",run_id] = total_load_e/1.0e6\n",
    "    run_stats.at[\"System available (TWh)\",run_id] = total_available_e/1.0e6\n",
    "    run_stats.at[\"System efficiency gross (%)\",run_id] = (total_load_e/total_available_e)*100.0\n",
    "        # \"gross\" includes dispatch down\n",
    "    run_stats.at[\"System dispatched (TWh)\",run_id] = total_dispatched_e/1.0e6\n",
    "    run_stats.at[\"System dispatched down (TWh)\",run_id] = total_undispatched_e/1.0e6\n",
    "    run_stats.at[\"System storage loss (TWh)\",run_id] = (total_dispatched_e-total_load_e)/1.0e6\n",
    "\n",
    "    run_stats.at[\"System efficiency net (%)\",run_id] = (total_load_e/total_dispatched_e)*100.0\n",
    "        # \"net\" of dispatch down\n",
    "    run_stats.at[\"System LCOE (â¬/MWh)\",run_id] = network.buses_t.marginal_price.mean()[ct]\n",
    "\n",
    "    snapshot_interval = run_configs.at['snapshot_interval',run_id]\n",
    "    weather_year_start = run_configs.at['weather_year_start',run_id]\n",
    "    weather_year_end = run_configs.at['weather_year_end',run_id]\n",
    "    Nyears = weather_year_end - weather_year_start + 1\n",
    "\n",
    "#    assumptions_year = int(scenario[:4])\n",
    "\n",
    "    assumptions = prepare_assumptions(Nyears=Nyears,\n",
    "                                      assumptions_year=run_configs.at['assumptions_year',run_id],\n",
    "                                      usd_to_eur=run_configs.at['usd_to_eur',run_id])\n",
    "\n",
    "#    if run_configs.at['steel_tanks',run_id] :\n",
    "#        assumptions.at[\"H2 storage\"] = assumptions.at[\"H2 steel tank storage\"]\n",
    "#    else:\n",
    "#        assumptions.at[\"H2 storage\"] = assumptions.at[\"H2 underground storage\"]\n",
    "    total_hours = network.snapshot_weightings.sum()\n",
    "    \n",
    "    gens = [\"wind\",\"solar\"]\n",
    "    for g in gens:\n",
    "        g_idx = ct + \" \" + g\n",
    "        run_stats.at[g+\" capacity nom (GW)\",run_id] = (\n",
    "            network.generators.p_nom_opt[g_idx]/1.0e3)\n",
    "        run_stats.at[g+\" available (TWh)\",run_id] = available_e[g_idx]/1.0e6\n",
    "        run_stats.at[g+\" dispatched (TWh)\",run_id] = dispatched_e[g_idx]/1.0e6\n",
    "        run_stats.at[g+\" penetration (%)\",run_id] = (dispatched_e[g_idx]/total_dispatched_e)*100.0 \n",
    "        run_stats.at[g+\" dispatched down (TWh)\",run_id] = (undispatched_e[g_idx])/1.0e6\n",
    "        run_stats.at[g+\" dispatched down (%)\",run_id] = (undispatched_frac[g_idx])*100.0\n",
    "        run_stats.at[g+\" capacity factor max (%)\",run_id] = (\n",
    "            network.generators_t.p_max_pu[g_idx].mean())*100.0\n",
    "        run_stats.at[g+\" capacity factor act (%)\",run_id] = (\n",
    "            dispatched_e[g_idx]/(network.generators.p_nom_opt[g_idx]*total_hours))*100.0\n",
    "        \n",
    "    run_stats.at[\"Battery charge/discharge (MW)\",run_id] = network.links.p_nom_opt[ct + \" battery charge\"]\n",
    "        # NB: battery charge are discharge p_nom are constrained to be equal, modulo efficiency\n",
    "    run_stats.at[\"Battery storage (MWh)\",run_id] = network.stores.e_nom_opt[ct + \" battery storage\"]\n",
    "    run_stats.at[\"P2H (electrolysis, GW)\",run_id] = (network.links.p_nom_opt[ct + \" H2 electrolysis\"]/1.0e3)\n",
    "    run_stats.at[\"H2P (H2 CCGT, GW)\",run_id] = (network.links.p_nom_opt[ct + \" H2 to power\"]/1.0e3)\n",
    "    run_stats.at[\"H2 store underground (TWh)\",run_id] = (network.stores.e_nom_opt[ct + \" H2 store underground\"]/1.0e6)\n",
    "    run_stats.at[\"H2 store tank (TWh)\",run_id] = (network.stores.e_nom_opt[ct + \" H2 store tank\"]/1.0e6)\n",
    "\n",
    "    return run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the system (interactive/single-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if/when desired to clear the accumulated run_configs and run_stats\n",
    "\n",
    "# FIXME: would like to have any way to shovel these result checkpoints out to \n",
    "# an external (persistent) data file?\n",
    "\n",
    "run_configs=pd.DataFrame()\n",
    "run_stats=pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually hardwired: ct='IE', wind dispatch priority, \n",
    "\n",
    "run_id = 'Test 001'\n",
    "\n",
    "# Note that pandas will tend to default to a float dtype throughout, even when an int is provided; \n",
    "# best coerce back to int on use, whenever needed, if important.\n",
    "run_configs.at['snapshot_interval', run_id] = 12 # hours\n",
    "# Available year(s) for weather data: solar 1985-2015 inclusive, wind 1980-2016\n",
    "run_configs.at['weather_year_start', run_id] = 2008 \n",
    "run_configs.at['weather_year_end', run_id] = 2008\n",
    "run_configs.at['load_year_start', run_id] = 2015\n",
    "run_configs.at['load_year_end', run_id] = 2015\n",
    "run_configs.at['assumptions_year', run_id] = 2030 # Used to select projected nominal cost \n",
    "run_configs.at['usd_to_eur', run_id] = 0.90 \n",
    "run_configs.at['h_store_underground_max_e (TWh)', run_id] = +np.inf\n",
    "run_configs.at['h_store_tank_max_e (TWh)', run_id] = 1.0 \n",
    "\n",
    "display(run_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = solve_network(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gather_run_stats(run_id,network)\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the system for a batch of parameterised runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configs = pd.DataFrame()\n",
    "run_id_stem = 'WY-'\n",
    "\n",
    "for weather_year_start in range(2007, 2015, 1) :\n",
    "    run_id = run_id_stem+str(weather_year_start)\n",
    "    run_configs.at['snapshot_interval', run_id] = 12 # hours\n",
    "    # Available year(s) for weather data: solar 1985-2015 inclusive, wind 1980-2016\n",
    "    run_configs.at['weather_year_start', run_id] = weather_year_start \n",
    "    run_configs.at['weather_year_end', run_id] = weather_year_start\n",
    "    run_configs.at['load_year_start', run_id] = 2015\n",
    "    run_configs.at['load_year_end', run_id] = 2015\n",
    "    run_configs.at['assumptions_year', run_id] = 2030 # Used to select projected nominal cost \n",
    "    run_configs.at['usd_to_eur', run_id] = 0.90 \n",
    "    run_configs.at['h_store_underground_max_e (TWh)', run_id] = +np.inf\n",
    "    run_configs.at['h_store_tank_max_e (TWh)', run_id] = 1.0 \n",
    "\n",
    "display(run_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_stats = pd.DataFrame()\n",
    "for run_id in run_configs.columns :\n",
    "    print(run_id)\n",
    "    network = solve_network(run_id)\n",
    "    gather_run_stats(run_id,network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(run_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra outputs (WHOBS legacy)\n",
    "\n",
    "**FIXME:** Need to review which - if any - of these are still relevant in WHOBS-IE-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#absolute market value in EUR/MWh\n",
    "(network.generators_t.p.multiply(network.buses_t.marginal_price[ct],axis=0).sum()/network.generators_t.p.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market cost in EUR/MWh (LCOE) - \n",
    "# for long-term equilibrium without additional constraints, same as market value\n",
    "(network.generators.capital_cost*network.generators.p_nom_opt)/network.generators_t.p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative market value\n",
    "(network.generators_t.p.multiply(network.buses_t.marginal_price[ct],axis=0).sum()/\n",
    "     network.generators_t.p.sum())/network.buses_t.marginal_price[ct].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative market value\n",
    "(network.links_t.p0.multiply(network.buses_t.marginal_price[ct],axis=0).sum()/\n",
    "     network.links_t.p0.sum())/network.buses_t.marginal_price[ct].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "#start = \"2015-01-01\"\n",
    "#stop = \"2015-12-31\"\n",
    "start = F\"{year_start}-01-01\"\n",
    "stop = F\"{year_end}-12-31\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.set_size_inches((10,8))\n",
    "\n",
    "\n",
    "rename = {\"wind\" : \"onshore wind\",\n",
    "          \"solar\" : \"utility solar PV\",\n",
    "          \"battery discharge\" : \"battery discharge\",\n",
    "          \"battery charge\" : \"battery charge\",\n",
    "          \"H2 electrolysis\" : \"hydrogen electrolysis\",\n",
    "          \"H2 to power\" : \"hydrogen turbine\"}\n",
    "\n",
    "rename = {ct + \" \"+k : v for k,v in rename.items()}\n",
    "\n",
    "rename[ct] = \"load\"\n",
    "\n",
    "colors = {\"onshore wind\" : \"b\",\n",
    "           \"utility solar PV\" : \"y\",\n",
    "           \"battery discharge\" : \"gray\",\n",
    "           \"battery charge\" : \"gray\",\n",
    "           \"load\" : \"k\",\n",
    "           \"hydrogen electrolysis\" : \"m\",\n",
    "           \"hydrogen turbine\" : \"r\"\n",
    "          }\n",
    "\n",
    "\n",
    "# FIXME: for some reason (solver tolerance?) some solution values that should be strictly \n",
    "# positive or negative may be infinitesimally (< 10e-10) of the other sign. This will cause \n",
    "# df.plot(stacked=True) to throw an error (requires all values to have same sign, positive or \n",
    "# negative). So we do an ugly \".round(10)\" to fix it...\n",
    "\n",
    "positive = pd.concat((network.generators_t.p,-network.links_t.p1[[ct+\" H2 to power\",ct+\" battery discharge\"]]),\n",
    "                     axis=1).rename(columns=rename).round(10)\n",
    "negative = pd.concat((-network.loads_t.p,-network.links_t.p0[[ct+\" H2 electrolysis\",ct+\" battery charge\"]]),\n",
    "                     axis=1).rename(columns=rename).round(10)\n",
    "\n",
    "print((abs(positive.sum(axis=1) + negative.sum(axis=1)) > 0.1).any())\n",
    "\n",
    "positive.loc[start:stop].plot(kind=\"area\",stacked=True,ax=ax,linewidth=0,\n",
    "                              color=[colors[i] for i in positive.columns])\n",
    "\n",
    "negative.loc[start:stop].plot(kind=\"area\",stacked=True,ax=ax,linewidth=0,\n",
    "                              color=[colors[i] for i in negative.columns])\n",
    "\n",
    "ax.set_ylim([-2.0*load_max,+2.0*load_max])\n",
    "ax.set_xlim([start,stop])\n",
    "ax.set_ylabel(\"Dispatch (generation is +ve, demand is -ve) [MW]\")\n",
    "ax.legend(ncol=3,loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.savefig(\"img/{}-{}-{}-{}.png\".format(ct,scenario,start,stop),dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses_t.marginal_price.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses_t.marginal_price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links_t.p0.mean()/network.links.p_nom_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "opt_costs = pd.Series()\n",
    "\n",
    "\n",
    "opt_costs = pd.concat((opt_costs,network.generators.capital_cost*network.generators.p_nom_opt))\n",
    "\n",
    "opt_costs = pd.concat((opt_costs,network.links.capital_cost*network.links.p_nom_opt))\n",
    "\n",
    "opt_costs = pd.concat((opt_costs,network.stores.capital_cost*network.stores.e_nom_opt))\n",
    "\n",
    "\n",
    "(opt_costs/opt_costs.sum()).plot(kind=\"bar\",grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections (random, possibly defunct!)\n",
    "\n",
    "+ I don't really have a good intuition for why battery storage is being used at the level it is. Presumably if we go to more coarse-grained temporal resolution it stops being used altogether?\n",
    "+ Battery and DSM (including heating and vehicle charging flexibilities) presumablly all fall into the same ~24 hour flexibility regime.\n",
    "+ Flow batteries would, presumably, have a quite different profile: maybe conceivably competitive with ammonia? Could we add a model of that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
